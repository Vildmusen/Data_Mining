{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix next banger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Netflix is a member-based internet entertainment service founded in 1997. The service allows members to watch tv-series, movies and documentaries through a streaming software on internet-connected devices against a monthly fee. Netflix’s content relies on a complex structure of algorithms that watches customer’s online use and are supposed to optimize satisfying decisions. Thus the company is in great need of user data. (Clares-Gavilán, Fernández-Manzano och Neira 2016, 568-576)\n",
    "\n",
    "The company’s operational environment is characterized by hands-off approach to management. The workforce is heterogeneous, about 3,500 people who \n",
    "leaders trust to have the company’s best interests at heart and act correspondingly. (Gulati 2018, 4-13).  Furthermore a majority of Netflix’s content is from outside sources and the company’s operational flexibility is limited by outside partners (Ciejka 2018, 3-38).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description\n",
    "\n",
    "As an effect of high competition and slow growth in the number of new subscribers Netflix share price has declined in fall 2019, hence Netflix wants to maximize the success of their next creation. The problem lies in not knowing what will be best received by the public. (Ny Teknik, 2019)\n",
    "\n",
    "Additionally, by having some of its content come from outside sources, part of the problem becomes choosing the right content. If Netflix have to choose between several newly released movies or series, how will they know which one has the best chance of success?\n",
    "\n",
    "In our project we will gather data from movies and their scripts. We will look for commonly used words, actors, genres and directors to predict which attributes Netflix should be the most interested in when creating their next movie and also which outside-produced movies they should add to their assortment. Finally upcoming movies will also be discussed with our analysed data in mind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Studies\n",
    "There are many different researches that has been carried out in the field using different approaches. Most of the studies found focuses on extracting data from social media to map how users online discussions, like reviews etc can predict a movies success. There are fewer studies that focuses on the attributes of a movie to explore how this is related to a movies success. \n",
    "\n",
    "In Ahmad et. al’s study Movie Success Prediction Using Data Mining (2017) the authors presents a study which aims to predict a movies success based on the weighted attributes budget, actors, director, producer, set locations, story writer, movie release day, competing movie releases at the same time, music, release location and target audience. The weighing is done using a mathematical model. It’s stated that “success cannot be predicted based on a particular attribute” and therefore weighing of multiple attributes will be integrated in this study as well. Furthermore the study gives a basic framework in how to value different attributes and what method to consider for the data mining. Lastly, the article shows how classification and clustering can be used in the context of prediction. It also gives a reference point to compare the results of this study to. \n",
    "\n",
    "Another similar study is Hammad Afzals article Prediction of Movies popularity Using Machine Learning Techniques (2016) which describes how machine learning approaches can predict an movies success based on datasets of IMDB scores and attributes. The most important finding of this article regarding the work of this report is that the attributes which contributed with most information was metascore and number of votes for each movie, Oscar awards won by the movies and the number of screens the movie is going to be screened which is considered in the choosing of attributes for this report. \n",
    "\n",
    "Furthermore Meenakshi et al also try to determine a movies success using several of the same attributes in their 2018 study. In the paper A Data mining Technique for Analyzing and Predicting the success of Movie they employ a decision tree together with clusters to categorize movies as either “Flop”, “Average” or “Hit”. They found that budget was no indication of how well a movie would be rated, and that genre was the most important node in their decision tree. (Meenakshi et al. 2018, 1-6)\n",
    "\n",
    "The paper Predicting movie success and academy awards through sentiment and social network analysis talks about how much influence online communities have on the actual success of movies. The paper focuses on a model that that predicts academy award nominees by researching the opinions of online communities. Afterwards it uses the same approach to see if there is a correlation between online communities and movie success at the box office. By doing this, the study were able to predict different real events, such as nine academy award winners, by considering and using mentioned models on social networks in movie communities online.(Jonas Sebastian Krauss et al. 2008, 9-10). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "\n",
    "importing data from 4 separate tables: \n",
    " - movies_metadata, containing several diffrerent attributes\n",
    " - title_principals, containing a connection between a movie and its cast members\n",
    " - movie_names, containing information about cast members\n",
    " - box_office // TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "movie_data = []\n",
    "title_principals = []\n",
    "movie_names = []\n",
    "\n",
    "with open('movies_metadata.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        movie_data.append(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('title_principals.tsv', encoding=\"utf8\") as tsvfile4:\n",
    "    reader_titles = csv.reader(tsvfile4, delimiter='\\t')\n",
    "    for row in reader_titles:\n",
    "        title_principals.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movie_names.tsv', encoding=\"utf8\") as tsvfile4:\n",
    "    reader_rating = csv.reader(tsvfile4, delimiter='\\t')\n",
    "    for row in reader_rating:\n",
    "        movie_names.append(row)\n",
    "        \n",
    "movie_data_np = np.array(movie_data[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin our extraction by taking the movie_metadata table and selecting a few wanted attributes. The genres are clumped together in an ugly anonymous type-like object, so we split it up and save only the attribute names in an array. More filtering is done by first sorting the movies on imdb's id for later, and then removing any movie with a rating below 7.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter attributes done!\n",
      "Genre rearranged done!\n",
      "Filter movies below 7 done!\n"
     ]
    }
   ],
   "source": [
    "movie_data_selected_attributes = []\n",
    "\n",
    "# Selecting attributes\n",
    "for movie in movie_data_np:\n",
    "    if(len(movie) > 22):\n",
    "        movie_data_selected_attributes.append([movie[6], movie[3], movie[8], movie[14], movie[22], movie[23]])\n",
    "\n",
    "print(\"Filter attributes done!\")\n",
    "        \n",
    "movie_data_stripped_genres = []\n",
    "\n",
    "# Rearranging genres\n",
    "for movie in movie_data_selected_attributes:\n",
    "    genre_arr = movie[1].split('\\'')\n",
    "    genres = []\n",
    "    for i in range(5, len(genre_arr), 6):\n",
    "        genres.append(genre_arr[i])       \n",
    "    movie_data_stripped_genres.append([movie[0], genres, movie[2], movie[3], movie[4], movie[5]])\n",
    "\n",
    "print(\"Genre rearranged done!\")    \n",
    "\n",
    "movies_above_7 = []\n",
    "\n",
    "def custom_sort(t):\n",
    "    return t[0]\n",
    "\n",
    "def try_parse_float(input):\n",
    "    try:\n",
    "        number = float(input)\n",
    "    except:\n",
    "        number = -1\n",
    "    return number\n",
    "\n",
    "movie_data_stripped_genres.sort(key=custom_sort)\n",
    "\n",
    "# Filter out movies with rating < 7.0\n",
    "for movie in movie_data_stripped_genres:\n",
    "    if(try_parse_float(movie[4]) >= 7.0):\n",
    "        movies_above_7.append(movie)\n",
    "\n",
    "print(\"Filter movies below 7 done!\")\n",
    "movies_above_7 = movies_above_7[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to help compare on ids. All imdb-ids consist of \"xx0124002\" where x is a letter. With this function we iterate through title_principals, the list with all connections, and movies_above_7, our filtered, sorted, list of movies. The connection is made by comparing ids from both lists, where movie_id iterates to \"catch up\" to title_id since many there are many more titles than movies in our lists.\n",
    "\n",
    "The list with movie list is then filtered to remove any movie that did not have a corresponding crew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number(string):\n",
    "    try:\n",
    "        return (int) (string[2:])\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "movies_with_crew = []\n",
    "\n",
    "# Iterate through title_principals and movies_above_7, join on id.\n",
    "j = 0\n",
    "movie_id = 0\n",
    "for i in range(len(title_principals)):\n",
    "    title_id = get_number(title_principals[i][0])\n",
    "    while(movie_id < title_id):\n",
    "        j += 1\n",
    "        if(j > len(movies_above_7) -1):\n",
    "            break\n",
    "        movie_id = get_number(movies_above_7[j][0])\n",
    "    if(movie_id == title_id):\n",
    "        if(j > len(movies_above_7) -1):\n",
    "            break\n",
    "        movies_above_7[j].append(title_principals[i][2])\n",
    "        \n",
    "movies_with_actors = []\n",
    "\n",
    "# Remove non-matches, missing values\n",
    "for movie in movies_above_7:\n",
    "    if(len(movie) > 6):\n",
    "        movies_with_actors.append(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list is saved as \"movies_and_crew.csv\" to not have to do this tedious task again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movies_and_crew.csv', 'w', encoding='utf-8') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(movies_with_actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read movies_and_crew:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_and_crew = []\n",
    "\n",
    "with open('movies_and_crew.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if(len(row) > 0):\n",
    "            movies_and_crew.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out movies before 1960. Remove all non-actors from movie_names. Defines a function to look for an array of actor ids and return corresponding names. Loop breaks early if index at actor_id is reached, since the actor list is sorted we can assume no actor is beyond their own id as index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_after_1960 = []\n",
    "\n",
    "# Remove movies before 1960\n",
    "for movie in movies_and_crew:\n",
    "    if(try_parse_float(movie[3].split('-')[0]) >= 1960):\n",
    "        movies_after_1960.append(movie)\n",
    "    \n",
    "movie_names_actors = []\n",
    "\n",
    "# Remove non-actors\n",
    "for name in movie_names:\n",
    "    if(\"actor\" in name[4] or \"director\" in name[4]):\n",
    "        movie_names_actors.append(name)\n",
    "    \n",
    "# Takes a list of actor-ids and returns an array of names\n",
    "def get_actor_names(actorList):\n",
    "    actors = []\n",
    "    for actor in actorList:\n",
    "        actor_id = get_number(actor)\n",
    "        count = 0\n",
    "        for name in movie_names_actors:\n",
    "            count += 1\n",
    "            if(count > actor_id):\n",
    "                break\n",
    "            if(actor == name[0]):\n",
    "                actors.append(name[1])\n",
    "                break\n",
    "    return actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect all actors in the movie on id and replace with names of actors in initial array. To do this, first the movie_names list is filtered to remove any non-actor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_actor_names = []\n",
    "\n",
    "# Replace actor ids with names\n",
    "for movie in movies_after_1960:\n",
    "    actors = get_actor_names(movie[6:])\n",
    "    movies_with_actor_names.append([movie[:5], actors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaaaand we save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movies_and_crew_names.csv', 'w', encoding='utf-8') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(movies_with_actor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "movies_with_actor_names = []\n",
    "\n",
    "with open('movies_and_crew_names.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if(len(row) > 0):\n",
    "            movies_with_actor_names.append(row)\n",
    "\n",
    "movies_with_actor_names = movies_with_actor_names[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaaaand we did something wrong when we saved it... Cleaning up some chars and setting up the rows again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_doing_this_again = []\n",
    "\n",
    "for values in movies_with_actor_names:\n",
    "    for value in values:\n",
    "        value = value.replace('\\'', '')\n",
    "        value = value.replace('\"', '')\n",
    "        value = value.replace('[', '')\n",
    "        value = value.replace(']', '')\n",
    "        value = value.replace(' ', '')\n",
    "        values = value.split(',')\n",
    "        we_doing_this_again.append(values)\n",
    "\n",
    "nice_and_clean = []\n",
    "\n",
    "for i in range(0, len(we_doing_this_again), 2):\n",
    "    nice_and_clean.append([we_doing_this_again[i], we_doing_this_again[i+1]])\n",
    "\n",
    "for values in nice_and_clean:\n",
    "    genres = []\n",
    "    for i in range(1, (len(values[0]) - 3)):\n",
    "        genres.append(values[0][i])\n",
    "    nr_of_genres = len(genres)\n",
    "    values[0] = [values[0][0], genres, values[0][1+nr_of_genres], values[0][2+nr_of_genres], values[0][3+nr_of_genres], values[1]]\n",
    "\n",
    "correct_format = []\n",
    "\n",
    "for value in nice_and_clean:\n",
    "    correct_format.append(value[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing table containing movie-director connections. Connecting all directors ids to their corresponding movies and then replaces the id with a name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_crews = []\n",
    "\n",
    "with open('data_crew.tsv', encoding=\"utf8\") as tsvfile4:\n",
    "    reader_titles = csv.reader(tsvfile4, delimiter='\\t')\n",
    "    for row in reader_titles:\n",
    "        movie_crews.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_with_directors = []\n",
    "\n",
    "def get_number(string):\n",
    "    try:\n",
    "        return (int) (string[2:])\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "# Iterate through all movies and movie_crews, join on movie id.\n",
    "j = 0\n",
    "crew_id = 0\n",
    "for i in range(len(correct_format)):\n",
    "    movie_id = get_number(correct_format[i][0])\n",
    "    while(crew_id < movie_id):\n",
    "        j += 1\n",
    "        if(j > len(movie_crews) -1):\n",
    "            break\n",
    "        crew_id = get_number(movie_crews[j][0])\n",
    "    if(crew_id == movie_id):\n",
    "        if(j > len(movie_crews) -1):\n",
    "            break\n",
    "        try:\n",
    "            correct_format[i].append(movie_crews[j][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movies_crew_and_director.csv', 'w', encoding='utf-8') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(correct_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "movies_with_directors = []\n",
    "\n",
    "with open('movies_crew_and_director.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if(len(row) > 0):\n",
    "            movies_with_directors.append(row)\n",
    "\n",
    "movies_with_directors = movies_with_directors[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching directors with name id in the same way we did with actors name id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_director_names(director):\n",
    "    director_id = get_number(director)\n",
    "    count = 0\n",
    "    for name in movie_names:\n",
    "        count += 1\n",
    "        if(count > director_id):\n",
    "            break\n",
    "        if(director == name[0]):\n",
    "            return name[1]\n",
    "    return \"\"\n",
    "\n",
    "movies_with_director_names = []\n",
    "\n",
    "# Replace actor ids with names\n",
    "for movie in movies_with_directors:\n",
    "    directors = get_director_names(movie[6])\n",
    "    movie[6] = directors\n",
    "    movies_with_director_names.append(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_directors\n",
    "\n",
    "with open('complete_array.csv', 'w', encoding='utf-8') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(movies_with_directors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "*Document you choice and motivation for selected data mining method(s) here. Choose a data mining method(s) to use in Python code to perform an analysis of your chosen dataset. Describe why you chose the method(s) and what interesting things you have found from the analysis.*\n",
    "\n",
    "*Replace the contents of this cell with your own text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of results\n",
    "\n",
    "*Document an evaluation your analysis results and describe how potentially actionable they are.*\n",
    "\n",
    "*Replace the contents of this cell with your own text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule and description of project plan\n",
    "\n",
    "*Rough schedule for the project beyond the pilot study presented in 3-5. This does not have to be advanced, you can simply provide an estimate based upon reported schedules for similar projects in the literature.*\n",
    "\n",
    "*Replace the contents of this cell with your own text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethical aspects that need to be considered\n",
    "\n",
    "*Are there ethical aspects that need to be considered? Are there legal implications (e.g., personal data / GDPR)? Are there implications if the case organization is a business, public authority, or nonprofit entity?*\n",
    "\n",
    "*Replace the contents of this cell with your own text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
